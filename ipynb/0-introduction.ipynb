{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5a74942cef8bedd80ad2acff3fc2941fd559c84f6c215ec02fd680d9314b7eb5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lesson 0\n",
    "## The main purpose of the original paper was to create fast and accurate real-time detector using only one GPU. The computations in algorithm should be parallelized as much as it posible. Also, the training process had to be proper and clear as is the use of the algorithm for inference.\n",
    "## As a result the authors achieved the following:\n",
    "### 1) Optimal tradeoff between speed and model performance is achieved. (All you need for training is 1080 Ti or 2080 Ti).\n",
    "### 2) Comparison and evaluation of Bag-of-Freebies and Bag-of-Specials methods.\n",
    "### 3) Reconstruction of current SotA methods to perform efficiently on a single GPU.\n",
    "## As stated in the original paper the YOLOv4 algorithm consists of 4 parts:\n",
    "### 1) [Backbone (CSPDarknet53)](./1-backbone.ipynb).\n",
    "### 2) SPP additional module.\n",
    "### 3) PANet path-aggregation neck.\n",
    "### 4) YOLOv3 head.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## What is Object Detection?\n",
    "\n",
    "Object Detection is a Computer Vision task. CV is one of the core aspects of Deep Learning. Its main goal of object detection is to understand which objects are presented in the image and what their location is.\n",
    "\n",
    "So, the former problem is called \"classification\". The aim of this process is to say what it is in image.\n",
    "\n",
    "Let's assume that we are gonna classify cat or dog in the image. The following picture illustrates classification problem:\n",
    "\n",
    "![Cat_classification](../img/classification.png)\n",
    "\n",
    "However, what if such image is presented?\n",
    "\n",
    "![no_class](../img/penguins.jpg =350x350) \n",
    "\n",
    "There are no cats or dogs on this image. Only penguins. However, since classificator `has` to say something, it will output either dog or cat. But both answers are wrong. Would be great if classificator could somehow say that there is nothing in the image.\n",
    "\n",
    "There are 2 ways to address this problem. Either we should\n",
    "- add another class representing 'nothing' OR\n",
    "- build classificator in such a way that each class will be represented by a confidence score from 0 to 1 independently. Low scores of all classes show that there is nothing in the image.\n",
    "\n",
    "In object detection we also want to receive information about where the object is in the image. It is called Object Localization.\n",
    "\n",
    "An example illustration is below:\n",
    "\n",
    "![localization](../img/localization.png)\n",
    "\n",
    "With `cat` label we also get the bounding box. The red square which represents object location.\n",
    "\n",
    "Traditionally, in classical computer vision systems the origin of coordinate system is located at the top left corner of the image:\n",
    "\n",
    "![origin](../img/coordinate_system.jpg)\n",
    "\n",
    "Usually, the bounding box information is represented in either:\n",
    "- (xmin, ymin, xmax, ymax) aka top-left and bottom right corners\n",
    "- (Xc, Yc, width, height) aka center coordinates\n",
    "\n",
    "The following equation transforms bounding box from one format to another\n",
    "\n",
    "Top-left corner:\n",
    "\n",
    "$ xmin = Xc - width/2 $\n",
    "\n",
    "$ ymin = Yc - height/2 $\n",
    "\n",
    "Bottom-right corner:\n",
    "\n",
    "$ xmax = Xc + width/2 $\n",
    "\n",
    "$ ymax = Yc + height/2 $"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### First exercise\n",
    "\n",
    "By using equations above transform move data from one coordinates to another"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS ###\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/answers')\n",
    "\n",
    "### DON'T REMOVE THIS CELL. JUST RUN IT ONCE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from introduction import transform_coordinates\n",
    "\n",
    "\n",
    "def transform_coordinates(arr):\n",
    "    \"\"\"\n",
    "    Transform coordinates from (xmin, xmax, ymin, ymax) to (Xc, Yc, width, height)\n",
    "    Input:\n",
    "        arr: np.array - shape is (n, 4) where n is amount of bounding boxes and 4 relates to coordinates\n",
    "    Output\n",
    "        transformed_arr: np.array - shape is (n, 4)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE ###\n",
    "\n",
    "    return transformed_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Now assume we want to receive information about multiple objects and their location.\n",
    "\n",
    "This is known as Object Detection task."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}