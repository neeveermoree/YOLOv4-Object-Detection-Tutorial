{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5a74942cef8bedd80ad2acff3fc2941fd559c84f6c215ec02fd680d9314b7eb5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### This is the final lesson with implementation of YOLO-v4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In Yolo-v3, the backbone-derived feature maps are then processed using an FPN-like structure.\n",
    "\n",
    "The main goal of such a solution is the Feature Pyramid Network's ability to collect as much information as possible from different levels of the backbone:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](../img/fpn.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Thus, the pyramidal structure of the hierarchy of features of convolutional layers is preserved simultaneously with strong semantic semantics at different levels of object recognition.\n",
    "\n",
    "FPN achieves the above benefits by combining low resolution feature maps but semantically strong features with high resolution feature maps but semantically weak features using top-down joins and side joins.\n",
    "\n",
    "Yolo-v4 does not use the Feature Pyramid Network as in Yolo-v3. The new version of the neural network uses Spatial Pyramid Pooling and Path Aggregation Network instead of FPN technology.\n",
    "\n",
    "These parts of the neural network are responsible for the correct final interpretation of the features received from the backbone to generate the most accurate predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The SPP block is an important part of the Yolo-v4 neural network algorithm, since its use adds to the functionality of the neural network the ability to process input images or video stream of any resolution.\n",
    "\n",
    "The input image format in Yolo-v3 is a resolution of 416x416 pixels. The described limitation is caused by the fact that at the stage of predicting the position of recognized objects in the image and their classes, fully connected layers of the neural network are used.\n",
    "\n",
    "Unlike convolutional layers used in early layers of neural network architectures, fully connected layers have a fixed input size. Because of this, the image must be exactly 416x416 pixels, otherwise the algorithm will complete its work with an error.\n",
    "\n",
    "To solve this problem, it is logical to either cut out the part of interest from the image (crop), or warp it to the desired resolution. Then you can observe the results of various deformations of the images.\n",
    "\n",
    "The given crop and warp for adjusting the image resolution for use in a neural network can greatly distort the original information. In this regard, the neural network will be trained on a low quality dataset, which will noticeably deteriorate the quality of the final prediction.\n",
    "\n",
    "![](../img/deformations.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Using the SPP block allows you to get rid of the problems described above. The SPP block is added after the last convolutional layer of the neural network.\n",
    "\n",
    "The SPP layer combines the final feature maps and creates a fixed-length representation of them for fully connected neural network layers. Thus, the Spatial Pyramid Pooling block performs a kind of aggregation of information collected in deep layers of the neural network between convolutional layers and fully connected layers to get rid of the need to use low-quality image transformations (for example, crop or wrap) before being fed into the algorithm as input parameters.\n",
    "\n",
    "![](../img/spp.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To implement the neck part in Yolo-v4 on the PyTorch framework, it is also necessary to pre-develop auxiliary modules that significantly simplify the architecture construction, reduce the amount of code and the possibility of making mistakes.\n",
    "\n",
    "First, I will implement the Upsample class, which, like all classes in the backbone, will inherit from the parent nn.Module class.\n",
    "\n",
    "The main purpose of this class is to reformat high-dimensional data matrices into a more workable format. Since the SPP block and other parts in the neck of Yolo-v4 often use the operations of gluing and concatenation, it is necessary to be able to quickly and correctly reformat the data dimension so that it matches the original feature map and the processed one.\n",
    "\n",
    "This is especially true in residual layers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Now let's implement utility class called UpSample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this class we want to manually change the way data is placed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Upsample, self).__init__()\n",
    "\n",
    "    def forward(self, x, target_size, inference=False):\n",
    "        \"\"\"\n",
    "        Reshape the values into right format\n",
    "        x: torch.Tensor - data\n",
    "        target_size: tuple(int[4]) - dimensions of new array\n",
    "        \"\"\"\n",
    "        assert (x.data.dim() == 4)\n",
    "        # _, _, tH, tW = target_size\n",
    "\n",
    "        if inference:\n",
    "\n",
    "            #B = x.data.size(0)\n",
    "            #C = x.data.size(1)\n",
    "            #H = x.data.size(2)\n",
    "            #W = x.data.size(3)\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "\n",
    "            pass\n",
    "        else:\n",
    "            return F.interpolate(x, size=(target_size[2], target_size[3]), mode='nearest')"
   ]
  },
  {
   "source": [
    "It is worth noting that in this implementation, there are no convolutional or fully connected layers of the neural network in the __init__ structure, therefore this class has no trainable parameters.\n",
    "\n",
    "However, the Upsample class can operate in two modes. The inference flag means that the input is used solely for making predictions. It also allows you to keep the original number of batches and channels of input data, thereby changing only the height and width of the array.\n",
    "\n",
    "Batches are nothing more than the number of images processed at a time by the neural network. The parameter of the number of batches can take on an arbitrarily large value, however, it is necessary to take into account the power of the computer used. As a rule, the batch parameter is a power of two, since when computations are parallelized, the GPU will process 25 or 32 images at the same time.\n",
    "\n",
    "The channels of the input data are a number that reflects the number of feature maps obtained in the previous step. The input image usually has three channels. These are the red, green, and blue color channels. Subsequently, the number of channels can be changed thanks to the convolutional layers of the neural network. The unchecked inference flag interpolates the input data to resize it into a more convenient format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In addition to the SPP block in the neck part of the Yolo-v4 neural network algorithm, PANet is used.\n",
    "\n",
    "The use of the PANet algorithm in Yolo-v4 is due to the fact that this algorithm is an improved version of the FPN algorithm. First, just like in the Feature Pyramid Network, a pyramidal structure is created for transmitting information from different convolutional layers of the neural network.\n",
    "\n",
    "However, after connections from top to bottom, an additional block follows, which collects signs even more efficiently, but already from bottom to top. The described solution helps to significantly improve the subsequent localization of objects. After that, all the final feature maps are combined using a special Adaptive Feature Pooling block, which allows restoring the lost initial information about the localization of objects in the deep layers of the neural network.\n",
    "\n",
    "The main difference from the FPN feature map collection architecture is that features from the image are collected exclusively from top to bottom, although this occurs at several levels. Path Aggregation Networks allow at the last level to collect features vice versa from bottom to top, thus preserving as much as possible information about the localization of objects from the first layers of the neural network, which have a weak representative ability, but have a large amount of information about the immediate boundaries of the object in the image. Further, the description of the architecture of the Path Aggregation Network is highlighted\n",
    "\n",
    "![](../img/panet.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The implementation of the methods described above for aggregating information from different feature maps is presented in the Neck class, which also inherits the base nn.Module class of the PyTorch framework.\n",
    "\n",
    "The functional description of the developed child class will be divided into 2 parts: the class constructor (__init__ method) and data processing (forward method)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(nn.Module):\n",
    "    def __init__(self, inference=False):\n",
    "        super().__init__()\n",
    "        self.inference = inference\n",
    "        \n",
    "        # !!!Use LeakyReLU activation function here\n",
    "\n",
    "        self.conv1 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv2 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv3 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=1, padding=5 // 2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=9, stride=1, padding=9 // 2)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=13, stride=1, padding=13 // 2)\n",
    "\n",
    "        # ADD your layers\n",
    "        self.conv4 = None  # 2048, 512\n",
    "        self.conv5 = None  # 512, 1024\n",
    "        self.conv6 = None  # 1024, 512\n",
    "        self.conv7 = None  # 512, 256\n",
    "        \n",
    "        # Initiate Upsample class here\n",
    "        self.upsample1 = None\n",
    "\n",
    "        self.conv8 = None  # 512, 256\n",
    "\n",
    "        self.conv9 = None  # 512, 256\n",
    "        self.conv10 = None  # 256, 512\n",
    "        self.conv11 = None  # 512, 256\n",
    "        self.conv12 = None  # 256, 512\n",
    "        self.conv13 = None  # 512, 256\n",
    "        self.conv14 = None  # 256, 512\n",
    "\n",
    "        self.upsample2 = None\n",
    "\n",
    "        # Same stuff with 256 and 128 feature maps\n",
    "        self.conv15 = None\n",
    "\n",
    "        self.conv16 = None\n",
    "        self.conv17 = None\n",
    "        self.conv18 = None\n",
    "        self.conv19 = None\n",
    "        self.conv20 = None\n",
    "\n",
    "    def forward(self, input, downsample4, downsample3, inference=False):\n",
    "        x1 = self.conv1(input)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x2)\n",
    "\n",
    "        m1 = self.maxpool1(x3)\n",
    "        m2 = self.maxpool2(x3)\n",
    "        m3 = self.maxpool3(x3)\n",
    "        # spp operation here (concatenation)\n",
    "        spp = None\n",
    "\n",
    "        x4 = self.conv4(spp)\n",
    "        x5 = self.conv5(x4)\n",
    "        x6 = self.conv6(x5)\n",
    "        x7 = self.conv7(x6)\n",
    "\n",
    "        up = self.upsample1(x7, downsample4.size(), self.inference)\n",
    "\n",
    "        x8 = self.conv8(downsample4)\n",
    "        \n",
    "        x8 = torch.cat([x8, up], dim=1)\n",
    "\n",
    "        x9 = self.conv9(x8)\n",
    "        x10 = self.conv10(x9)\n",
    "        x11 = self.conv11(x10)\n",
    "        x12 = self.conv12(x11)\n",
    "        x13 = self.conv13(x12)\n",
    "        x14 = self.conv14(x13)\n",
    "\n",
    "        up = self.upsample2(x14, downsample3.size(), self.inference)\n",
    "\n",
    "        x15 = self.conv15(downsample3)\n",
    "\n",
    "        x15 = torch.cat([x15, up], dim=1)\n",
    "\n",
    "        x16 = self.conv16(x15)\n",
    "        x17 = self.conv17(x16)\n",
    "        x18 = self.conv18(x17)\n",
    "        x19 = self.conv19(x18)\n",
    "        x20 = self.conv20(x19)\n",
    "        return x20, x13, x6"
   ]
  },
  {
   "source": [
    "In the description of the Neck class, you can immediately see the use of the Upsample utility class described above.\n",
    "\n",
    "The use of the SPP architecture in the Yolo-v4 neck computational graph is indicated by self.conv1-7 convolutional layers and multiple max pooling operations. The latter allow many times to reduce the dimension of the output arrays by aggregating features within a 2D window.\n",
    "\n",
    "Specifically, max pooling allocates the largest value in the window. The rest of the convolutional layers and objects of the Upsample class are used for more accurate aggregation of careers of features of different dimensions in Path Aggregation Networks.\n",
    "\n",
    "It is also worth paying attention to the fact that in the description of the Neck part, the activation function has been changed from Mish to LeakyReLU, since when training the classifier, LeakyReLU works more stably and faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The arguments of this method differ from the description of the forward methods of the above classes.\n",
    "\n",
    "In addition to the data itself, the method for processing also needs feature maps obtained as a result of the work of the previously presented DownSample3 and DownSample4 classes in order to preserve the hierarchical structure of features.\n",
    "\n",
    "The concept of an SPP block and its logic are described when concatenating data processed by different convolutional layers at different levels. When data is glued, the original layer of the feature map and 3 individually processed feature maps are fed to the input of the operation after the corresponding max pooling functions.\n",
    "\n",
    "Further, after the declaration of the first up variable and to the end of the forward method, there is a description of the Path Aggregation Network. Using the previously described Upsample functions and the results of the Downsample3 and Downsample4 classes, you can implement a hierarchical structure of collecting signs on the PANet principle.\n",
    "\n",
    "For this, feature maps obtained after the SPP block and from the two previous levels are used. Directly in the script, the functionality written with the x4 variable and until the end of the forward method of the Neck class is responsible for this. As a result of the method, 3 processed feature maps are returned, the data and information from which will subsequently be used to classify objects and regress their coordinates in the image."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In neural network algorithms for object recognition and detection, under head is meant the final part of the algorithm, which, based on the generated backbone feature maps and the most representatively collected and aggregated neck data block, produces the final model prediction.\n",
    "\n",
    "In the tasks of object recognition and detection, these are the classification of recognized objects and their position in the image.\n",
    "Yolo-v3 uses a unique head part that does an excellent job. In this regard, in Yolo-v4, it was decided to use the development from the previous version of the algorithm.\n",
    "\n",
    "The basic principle of operation of Yolo-v4 head is as follows: first, the image is divided into a grid, say 13x13 pixels, each cell contains n anchors, which are the basic answer of the algorithm for localizing objects.\n",
    "\n",
    "In fact, each anchor describes a region of the image in which a potential object lies. Yolo-v4 head uses 3 anchors for each grid cell. Then, using a single convolution operation for each grid cell and for each anchor, 5 + C variables are predicted, where C is the number of classes that the neural network is trained to recognize. Each number among these C values ​​lies in the range of admissible values ​​[0, 1], and their sum is necessarily equal to one. Thus, each of these values ​​is nothing more than the probability of a potential object belonging to a certain class.\n",
    "\n",
    "The remaining 5 values ​​are responsible for the x, y coordinates of the central point of the object, its dimensions in the image (length and width) and the probability of being within the boundaries of this particular cell and this particular anchor of the object. As a result the final dimension of the output array takes the following value: (13, 13, 3, 5 + C)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The described principle is repeated three times on different feature maps from different levels to simplify the prediction of objects of different sizes by the neural network.\n",
    "\n",
    "Also, the classifier is much more successful in predicting objects, the regions of localization in the image of which strongly overlap."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To implement the head part of the Yolo-v4 neural network, we will first develop the YoloLayer helper class, which will also inherit from the parent class nn.Module of the PyTorch library.\n",
    "\n",
    "The described class implements the functionality described earlier in this chapter for one of the feature maps. The implementation in the form of a script can be examined further: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolov4Head(nn.Module):\n",
    "    def __init__(self, output_ch, n_classes, inference=False):\n",
    "        super().__init__()\n",
    "        self.inference = inference\n",
    "\n",
    "        self.conv1 = Conv_Bn_Activation(128, 256, 3, 1, 'leaky')\n",
    "        self.conv2 = Conv_Bn_Activation(256, output_ch, 1, 1, 'linear', bn=False, bias=True)\n",
    "\n",
    "        self.yolo1 = YoloLayer(\n",
    "                                anchor_mask=[0, 1, 2], num_classes=n_classes,\n",
    "                                anchors=[12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401],\n",
    "                                num_anchors=9, stride=8)\n",
    "\n",
    "        self.conv3 = Conv_Bn_Activation(128, 256, 3, 2, 'leaky')\n",
    "\n",
    "        self.conv4 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv5 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv6 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv7 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv8 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv9 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv10 = Conv_Bn_Activation(512, output_ch, 1, 1, 'linear', bn=False, bias=True)\n",
    "        \n",
    "        self.yolo2 = YoloLayer(\n",
    "                                anchor_mask=[3, 4, 5], num_classes=n_classes,\n",
    "                                anchors=[12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401],\n",
    "                                num_anchors=9, stride=16)\n",
    "\n",
    "        self.conv11 = Conv_Bn_Activation(256, 512, 3, 2, 'leaky')\n",
    "\n",
    "        self.conv12 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv13 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv14 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv15 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv16 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv17 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv18 = Conv_Bn_Activation(1024, output_ch, 1, 1, 'linear', bn=False, bias=True)\n",
    "        \n",
    "        self.yolo3 = YoloLayer(\n",
    "                                anchor_mask=[6, 7, 8], num_classes=n_classes,\n",
    "                                anchors=[12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401],\n",
    "                                num_anchors=9, stride=32)\n",
    "\n",
    "    def forward(self, input1, input2, input3):\n",
    "        x1 = self.conv1(input1)\n",
    "        x2 = self.conv2(x1)\n",
    "\n",
    "        x3 = self.conv3(input1)\n",
    "\n",
    "        x3 = torch.cat([x3, input2], dim=1)\n",
    "        x4 = self.conv4(x3)\n",
    "        x5 = self.conv5(x4)\n",
    "        x6 = self.conv6(x5)\n",
    "        x7 = self.conv7(x6)\n",
    "        x8 = self.conv8(x7)\n",
    "        x9 = self.conv9(x8)\n",
    "        x10 = self.conv10(x9)\n",
    "\n",
    "        x11 = self.conv11(x8)\n",
    "\n",
    "        x11 = torch.cat([x11, input3], dim=1)\n",
    "\n",
    "        x12 = self.conv12(x11)\n",
    "        x13 = self.conv13(x12)\n",
    "        x14 = self.conv14(x13)\n",
    "        x15 = self.conv15(x14)\n",
    "        x16 = self.conv16(x15)\n",
    "        x17 = self.conv17(x16)\n",
    "        x18 = self.conv18(x17)\n",
    "        \n",
    "        if self.inference:\n",
    "            y1 = self.yolo1(x2)\n",
    "            y2 = self.yolo2(x10)\n",
    "            y3 = self.yolo3(x18)\n",
    "\n",
    "            return get_region_boxes([y1, y2, y3])\n",
    "        \n",
    "        else:\n",
    "            return [x2, x10, x18]"
   ]
  },
  {
   "source": [
    "This class works directly only with those anchors that were created on a specific feature map.\n",
    "\n",
    "Also, a threshold is used here, according to which it is considered whether a given object lies in a specific region or not. If the intersection (IoU or Intersection over Unit) is greater than the threshold, then the trained parameters of this region at a specific anchor on a specific feature map are updated to train the neural network.\n",
    "\n",
    "Now, using the YoloLayer class, you can implement the Yolov4Head class, which contains all the above operations and outputs neural network predictions in the form of classes of recognized objects and their localization in the image.\n",
    "\n",
    "Also, as in the case of the neck part of Yolo-v4, the head block will be represented as two methods: __init__ (constructor) and forward (data processing). Moreover, it also inherits the nn.Module base class. The implementation of the __init__ method is presented"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In the description of the class attributes, there are 3 objects of the YoloLayer class for predicting objects at different levels of the received feature maps. They differ in the input data and the size of the final localization of objects. The stride parameter increases with the depth of the feature maps.\n",
    "\n",
    "Thus, deeper feature maps are better at predicting the localization of small objects in the image, while earlier feature maps facilitate accurate prediction of large objects. It is also worth noting that the head block uses the LeakyReLU activation function as in the neck part, and not the Mish activation function as in the backbone. In addition, before the final prediction of the neural network at each of the levels, a linear function of activation of the identity display is used.\n",
    "\n",
    "In the implementation of the method, the previously described inference flag is used, which allows you to change the nature of the method depending on the type of neural network operation. When training, it is enough to return the obtained result for the operation of the error function and the backpropagation method; in turn, when the algorithm works directly in real-time prediction, it is necessary to correctly process the results for visual demonstration and further data processing. Also in this class, the Bottom Up part of the PANet architecture is visible when predicting features of different dimensions for several maps.\n",
    "\n",
    "So, the classes backbone, neck and head of the Yolo-v4 neural network algorithm were developed. Next comes the implementation of the final class Yolov4, which contains all the above classes and is a convenient add-on for further work with the neural network."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class Yolov4(nn.Module):\n",
    "    def __init__(self, yolov4conv137weight=None, n_classes=80, inference=False):\n",
    "        super().__init__()\n",
    "\n",
    "        output_ch = (4 + 1 + n_classes) * 3\n",
    "\n",
    "        # backbone\n",
    "        # Downsample classes\n",
    "        self.down1 = None \n",
    "        self.down2 = None\n",
    "        self.down3 = None\n",
    "        self.down4 = None\n",
    "        self.down5 = None\n",
    "\n",
    "        # neck\n",
    "        self.neck = None\n",
    "\n",
    "        if yolov4conv137weight:\n",
    "            _model = nn.Sequential(self.down1, self.down2, self.down3, self.down4, self.down5, self.neck)\n",
    "            pretrained_dict = torch.load(yolov4conv137weight)\n",
    "\n",
    "            model_dict = _model.state_dict()\n",
    "\n",
    "            pretrained_dict = {k1: v for (k, v), k1 in zip(pretrained_dict.items(), model_dict)}\n",
    "\n",
    "            model_dict.update(pretrained_dict)\n",
    "            _model.load_state_dict(model_dict)\n",
    "        \n",
    "        # YOLO-v4 class is here\n",
    "        self.head = None\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        d1 = self.down1(input)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "\n",
    "        x20, x13, x6 = self.neck(d5, d4, d3)\n",
    "\n",
    "        output = self.head(x20, x13, x6)\n",
    "        return output"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "source": [
    "This class uses objects of the backbone, neck and head classes.\n",
    "\n",
    "Also, a functional was developed for loading the weights of a pre-trained neural network to implement the transfer learning process, in which the model is trained not from a random point, but after training on a similar task.\n",
    "\n",
    "Thus, it is possible to achieve good recognition quality with a small amount of data. Also, the training of the neural network will be noticeably faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}